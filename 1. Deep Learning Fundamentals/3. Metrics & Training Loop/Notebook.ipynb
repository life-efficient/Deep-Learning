{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "perfect-farming",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "\n",
    "> PyTorch, out of the box, __does not provide any metrics for us to use__\n",
    "\n",
    "Statement above means that:\n",
    "- We have to create our own metrics from scratch\n",
    "- We can use third party module to do that for us\n",
    "\n",
    "First option is __error prone, time consuming__ and requires high attention to detail (as the metrics could be used in various settings).\n",
    "\n",
    "Let's see how one could design metric-like API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-sperm",
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "import torch\n",
    "\n",
    "class Metric(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        self.cache = 0\n",
    "        self.i = 0\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def forward(self, *args, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, logits, labels):\n",
    "        self.i += 1\n",
    "        self.cache += self.forward(logits.detach(), labels)\n",
    "\n",
    "    def evaluate(self):\n",
    "        result = self.cache / self.i\n",
    "        self.cache = 0\n",
    "        self.i = 0\n",
    "        return result\n",
    "\n",
    "\n",
    "class CrossEntropyLoss(Metric):\n",
    "    def forward(self, logits, labels):\n",
    "        return torch.nn.functional.cross_entropy(logits, labels, reduction=\"mean\")\n",
    "\n",
    "class Accuracy(Metric):\n",
    "    def forward(self, logits, labels):\n",
    "        return torch.mean((torch.argmax(logits, dim=-1) == labels).float())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "periodic-wellington",
   "metadata": {},
   "source": [
    "As one can see there are a few quirks, namely:\n",
    "- __accumulating values__ - each neural network outputs have to be gathered\n",
    "- __creating generic interface__ - so users can easily extend it with their own metrics\n",
    "\n",
    "Fortunately, tested, improved and maintained implementation are provided in [__`torchmetrics`__](https://torchmetrics.readthedocs.io/en/latest/) package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-bidder",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-latex",
   "metadata": {},
   "source": [
    "Usage consists of the following steps:\n",
    "1. Obtain outputs from neural network\n",
    "2. Obtain targets (classification, regression or any other task)\n",
    "3. Pass both through metric of choice\n",
    "4. __Repeat above steps for the whole dataset__\n",
    "5. __Obtain accumulated results__\n",
    "\n",
    "Let's see how one could do that via `torchmetrics`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immediate-convenience",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchmetrics\n",
    "\n",
    "# initialize metric\n",
    "metric = torchmetrics.Accuracy()\n",
    "\n",
    "n_batches = 10\n",
    "for i in range(n_batches):\n",
    "    # simulate a classification problem\n",
    "    preds = torch.randn(10, 5).softmax(dim=-1)\n",
    "    target = torch.randint(5, (10,))\n",
    "    # metric on current batch\n",
    "    acc = metric(preds, target)\n",
    "    print(f\"Accuracy on batch {i}: {acc}\")\n",
    "\n",
    "# metric on all batches using custom accumulation\n",
    "acc = metric.compute()\n",
    "print(f\"Accuracy on all data: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spanish-estate",
   "metadata": {},
   "source": [
    "Things to note:\n",
    "- __All `torchmetrics` are instances of `torch.nn.Module`__, they have to be assigned is used within another `torch.nn.Module`\n",
    "- `__call__` is used to calculate __per-batch metric__\n",
    "- `compute` is used to calculate __gathered metrics__ across multiple batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fancy-coating",
   "metadata": {},
   "source": [
    "# Tensorboard\n",
    "\n",
    "> __Tensorboard is a standalone GUI tool which allows us to visualize metrics (and other data)__\n",
    "\n",
    "Originally created for Tensorflow, after that widespread adoption and has an intergration for PyTorch ([`torch.utils.tensorboard`](https://pytorch.org/docs/stable/tensorboard.html) module).\n",
    "\n",
    "First, one has to install `tensorboard` separately in order to use this module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-czech",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "canadian-salvation",
   "metadata": {},
   "source": [
    "After that there are a few main steps:\n",
    "1. __Create `torch.utils.tensorboard.SummaryWriter` instance__ \n",
    "2. __Use it's specific methods to write data__\n",
    "\n",
    "Most of the methods have the following signature:\n",
    "\n",
    "```python\n",
    "write_{what}(\"name\", data, step)\n",
    "```\n",
    "\n",
    "where\n",
    "- `name` - Under which label should the data be logged to. __Nested labels allowed__, for example:\n",
    "    - `loss/training` - loss but for training phase\n",
    "    - `loss/validation` - loss but for validation phase\n",
    "- `data` - usually `torch.tensor` instances (`np.array`s allowed also)\n",
    "- `step` - __global step under which this data will be saved__. __Should be incremented on a per-batch basis (or per-epoch, depending what you want to do)__.\n",
    "\n",
    "Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-suffering",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "\n",
    "# By default data will be saved in \"./runs\" folder\n",
    "writer = SummaryWriter()\n",
    "\n",
    "for n_iter in range(100):\n",
    "    writer.add_scalar('Loss/train', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Loss/test', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Accuracy/train', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Accuracy/test', np.random.random(), n_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-cartoon",
   "metadata": {},
   "source": [
    "After our data has been gathered one can visualize the results.\n",
    "\n",
    "First, within Google Colab one can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-brand",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google colab\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confident-video",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-ecuador",
   "metadata": {},
   "source": [
    "From `localhost` via `cmdline`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "periodic-christmas",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-shade",
   "metadata": {},
   "source": [
    "# Saving data\n",
    "\n",
    "> __PyTorch allows us to easily save data via `pickle` based interface__\n",
    "\n",
    "Usually one would like to save:\n",
    "- `torch.nn.Module` instances after training (for later re-use)\n",
    "- `torch.optim.Optimizer` instances in order to restart the training\n",
    "\n",
    "> __`.pt` is the preffered extension to save your data via PyTorch__\n",
    "\n",
    "## torch.save & torch.load\n",
    "\n",
    "> __Easiest (yet not the best) method to save our data__\n",
    "\n",
    "Simple `torch.save(data, path)` can be used to save:\n",
    "- `torch.Tensor` instances (our metrics)\n",
    "\n",
    "Let's see how one could do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "further-sampling",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-22T12:05:13.253754Z",
     "start_time": "2021-06-22T12:05:11.587299Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.randn(20)\n",
    "torch.save(data, \"tensor.pt\")\n",
    "\n",
    "loaded = torch.load(\"tensor.pt\")\n",
    "\n",
    "data == loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-graphics",
   "metadata": {},
   "source": [
    "## state_dict\n",
    "\n",
    "> __In PyTorch, `state_dict` should be used to save models, optimizers and other \"more stateful\" objects (usually those inheriting from `torch.nn.Module`)__\n",
    "\n",
    "Why?\n",
    "- PyTorch loads data __but__ definitions of objects are loaded as code (e.g. you need access to source code of your model before loading it)\n",
    "- If we simply use `torch.save(model, \"model.pt\")` __our parameters saved will be bound to specific code version__\n",
    "- If we were to change the model architecture (e.g. to refactor the code) __`torch.load` would crash!__\n",
    "\n",
    "> __`state_dict` is Python dictionary containing ONLY PARAMETERS & BUFFERS (e.g. weights) which one can load to models WHICH HAVE THE SAME LAYER LAYOUT__\n",
    "\n",
    "Let's see an example of how one could do that (including restoration):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-policy",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(20, 20), torch.nn.ReLU(), torch.nn.Linear(20, 1)\n",
    "        )\n",
    "\n",
    "\n",
    "torch.save(\n",
    "    ExampleModel().state_dict(), \"model.pt\"\n",
    ")\n",
    "\n",
    "model = ExampleModel()\n",
    "model.load_state_dict(torch.load(\"model.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neutral-green",
   "metadata": {},
   "source": [
    "## Saving multiple objects\n",
    "\n",
    "> __`torch.save` can be used to save multiple data points creating a generic CHECKPOINT__\n",
    "\n",
    "In order to create a checkpoint we simply __save dictionary containing our objects__.\n",
    "\n",
    "Let's see how this looks in practice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valued-attachment",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "    {\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"loss\": loss,\n",
    "    },\n",
    "    PATH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-nation",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TheModelClass(*args, **kwargs)\n",
    "optimizer = TheOptimizerClass(*args, **kwargs)\n",
    "\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indonesian-economics",
   "metadata": {},
   "source": [
    "# Training and Evaluation\n",
    "\n",
    "Now we almost have all of the necessary pieces to work with neural networks:\n",
    "- __Basics of PyTorch__\n",
    "- __Basic neural network for tabular data__ - `torch.nn.Module`, `torch.nn.Linear` and `torch.nn.Sequential`\n",
    "- __Datasets & DataLoaders__ - how to create batches of examples for our neural network\n",
    "- __Optimization procedure__ - how to optimize our neural network\n",
    "- __Measuring it's performance__ - using `torchmetrics`\n",
    "- __Saving metric values__ - using `tensorboard`\n",
    "- __Saving and loading checkpoints__ - using `torch.save` and `torch.load`\n",
    "\n",
    "Last thing we're missing is how to actually `train` on our dataset and `evaluate` on validation and/or test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charitable-sunday",
   "metadata": {},
   "source": [
    "## model.train() and model.eval()\n",
    "\n",
    "> `model.train()` changes mode of the model to training\n",
    "\n",
    "What does that mean? \n",
    "- Some layer behave differently based on whether we train them or use them for evaluation (we will see `Dropout` and `BatchNorm` in the next chapter)\n",
    "\n",
    "Analogously `model.eval()` turns on evaluation mode.\n",
    "\n",
    "> __Remember to always change model's mode before specific phase!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "rough-annex",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-22T12:40:40.264865Z",
     "start_time": "2021-06-22T12:40:40.253184Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.4591, -0.0000,  2.3225,  1.5816,  0.0000, -2.1619, -0.8403,  0.0000,\n",
      "          3.1002, -0.2020, -0.0000, -0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         -0.0000,  1.6939, -0.3198,  2.4890],\n",
      "        [-0.0000,  0.0000,  0.0000, -0.0000, -0.9355, -0.0000,  0.0000,  2.0543,\n",
      "          0.0000, -1.2924, -1.5273,  1.3543,  0.0000, -0.4998,  2.8455, -0.5934,\n",
      "          0.0000, -0.0000, -0.0000, -0.0000],\n",
      "        [-0.5197, -0.8565, -0.0144,  0.0000, -0.0000, -0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.1857, -0.5098,  0.0000, -0.0000,  1.6102,  0.0000, -0.0000,\n",
      "         -0.0000, -0.9521,  0.1253, -0.4957]], grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2295, -0.3679,  1.1612,  0.7908,  0.0706, -1.0809, -0.4202,  1.1120,\n",
       "          1.5501, -0.1010, -1.0078, -0.0088,  0.5752,  0.5799,  1.0626,  0.9444,\n",
       "         -0.2436,  0.8470, -0.1599,  1.2445],\n",
       "        [-1.0470,  0.0079,  0.5864, -0.2979, -0.4678, -0.2323,  1.0144,  1.0272,\n",
       "          0.6973, -0.6462, -0.7636,  0.6771,  0.0994, -0.2499,  1.4227, -0.2967,\n",
       "          0.1265, -0.1090, -0.8705, -0.0624],\n",
       "        [-0.2599, -0.4282, -0.0072,  0.3843, -0.0788, -0.5478,  0.6889,  0.5713,\n",
       "          0.6715,  0.0929, -0.2549,  0.3580, -0.7167,  0.8051,  0.1825, -0.8064,\n",
       "         -0.5278, -0.4760,  0.0626, -0.2479]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.randn(3, 5)\n",
    "model = torch.nn.Sequential(torch.nn.Linear(5, 20), torch.nn.Dropout(p=0.5))\n",
    "\n",
    "model.training() # Default mode\n",
    "training = model(data)\n",
    "model.eval()\n",
    "evaluation = model(data)\n",
    "\n",
    "print(training)\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "editorial-gabriel",
   "metadata": {},
   "source": [
    "## torch.no_grad\n",
    "\n",
    "> `torch.no_grad()` is a context manager (and decorator) __used to turn off gradient tape recording__\n",
    "\n",
    "While this operation does not influence the results it has additional properties:\n",
    "- Performance improvement as the operations are not recorded __as we won't backpropagate through it__\n",
    "- Allows us not to traverse through graph second time (which raises an error)\n",
    "\n",
    "> __Due to above reasons always use it when evaluating model performance!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "needed-exposure",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-22T12:52:48.087669Z",
     "start_time": "2021-06-22T12:52:48.080724Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1.], requires_grad=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y = x * 2\n",
    "    \n",
    "y.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-probability",
   "metadata": {},
   "source": [
    "And as a decorator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "copyrighted-hazard",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-22T12:52:58.841399Z",
     "start_time": "2021-06-22T12:52:58.837267Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def doubler(x):\n",
    "    return x * 2\n",
    "\n",
    "z = doubler(x)\n",
    "z.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "posted-painting",
   "metadata": {},
   "source": [
    "## Basic training loop\n",
    "\n",
    "Let's assume we have our data already in place (we will use `torch.random.randn` as input, __usually we would use `torch.utils.data.DataLoader` for that!__).\n",
    "\n",
    "Basic idea is as follows:\n",
    "- setup necessary objects (metrics, summary writer, criterions (loss functions), model, optimizer)\n",
    "- For training:\n",
    "    - Turn on `model.train()` before you start training (default mode, but good practice to be explicit about it)\n",
    "    - Loop over `torch.utils.data.DataLoader` getting samples and targets\n",
    "    - Pass them through neural network\n",
    "    - Calculate `loss` based on `criterion`\n",
    "    - `loss.backward()` to obtain gradient of loss w.r.t. model's parameters (weights)\n",
    "    - `optimizer.step()` to apply gradient modifying weights based on optimizer's formula\n",
    "    - __`optimizer.zero_grad()`__ - zeroes out gradient contained in parameters (otherwise it would be accumulated during next pass and would become too large and destroy network's parameters during update)\n",
    "- For evaluation (__validation & test work the same but on different datasets!__) everything works the same __except__:\n",
    "    - We turn on `model.eval()` at the beggining of evaluation\n",
    "    - We use `torch.no_grad()` context manager __on whole `DataLoader` pass__\n",
    "\n",
    "Below is a \"standard\" (skeletonized) training loop for regression tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-boston",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# Dummy data\n",
    "# Usually we iterate over\n",
    "X, y = torch.randn(64, 15), torch.randn(64)\n",
    "X, y = X.to(device), y.to(device)\n",
    "\n",
    "# Iterate for 20 epochs over WHOLE DATASET\n",
    "for epoch in range(20):\n",
    "    outputs = model(X)\n",
    "    loss = criterion(outputs, y)\n",
    "    \n",
    "    # Perform backpropagation\n",
    "    loss.backward()\n",
    "    \n",
    "    # Perform optimization step & zero-out gradient\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    print(f\"EPOCH: {epoch} | LOSS: {loss.detach()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infinite-opinion",
   "metadata": {},
   "source": [
    "> __Please notice DATA has to be explicitly casted to the device of choice!__\n",
    "\n",
    "> __Please notice MODEL has to be explicitly casted to the device of choice!__\n",
    "\n",
    "> __`torch.utils.data.DataLoader` DOES NOT automatically cast tensors to device!__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "refined-segment",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "> __Create full training and evaluation system for PyTorch!__\n",
    "\n",
    "## Data\n",
    "\n",
    "- Use [`sklearn.datasets.load_digits`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html#sklearn.datasets.load_digits) and wrap it with appropriate `torch.utils.data.Dataset`\n",
    "- Split dataset using `torch.utils.data.random_split`\n",
    "- After that create three separate `torch.utils.data.DataLoader`s instances\n",
    "\n",
    "## Model\n",
    "\n",
    "Create a neural network containing a few layer with appropriate shapes for this classification task.\n",
    "\n",
    "Add the following methods:\n",
    "- `forward` - returns logits\n",
    "- `predict_proba` - returns probabilities\n",
    "- `predict` - returns predicted class per-example\n",
    "\n",
    "## Setup\n",
    "\n",
    "Create necessary variables, namely:\n",
    "- `torch.device` (gpu if available)\n",
    "- `criterion` - appropriate loss function for our task\n",
    "- `optimizer`- method to update our neural network\n",
    "\n",
    "## Training & evaluation\n",
    "\n",
    "### Abstract Base Class\n",
    "\n",
    "Create an abstract base class called `System` (inherit from `abc.ABC` and mark methods to implement for users via `abc.abstractmethod` decorator) which:\n",
    "- Defines `__init__` method which takes:\n",
    "    - `model`\n",
    "    - `optimizer`\n",
    "    - `device`\n",
    "    - `criterion`\n",
    "    - `writer` - `tensorboard` SummaryWriter\n",
    "    - `metrics` - this one is a dictionary with three keys: `[train, validation, test]`) and each having a list of metrics which we will use for separate pipeline steps\n",
    "- Defines `train` method which gets a single argument (`dataloader`) and:\n",
    "    - sets up `model.train()`\n",
    "    - iterates over `dataloader`\n",
    "    - passes `batch` from dataloader to `train_step` function\n",
    "    - gets output from `train_step` which is our `loss` value\n",
    "    - performs `backward()` on loss\n",
    "    - uses `optimizer` to perform updates\n",
    "- Defines `validate` method which gets a single argument (`dataloader`) and:\n",
    "    - sets up `model.eval()` and is wrapped with `torch.no_grad`\n",
    "    - iterates over `dataloader`\n",
    "    - passes `batch` from dataloader to `validate_step` function\n",
    "- Defines `test` method which is the same as above but uses `test_step` (how to remove unnecessary code duplication?)\n",
    "- Specifies `train_step`, `validation_step` and `test_step` as abstract methods (inheriting class needs to overwrite them)\n",
    "\n",
    "### Concrete implementation\n",
    "\n",
    "Inherit from `System` (name this class `ClassificationSystem`) and implement `train_step`, `validation_step` and `test_step`:\n",
    "- Each of them has to use appropriate `self.metrics` key and calculate their metrics\n",
    "- Log metrics to summary writer based on it's key (e.g. `train`) and name of the metric (e.g. `accuracy`). This would become `train/accuracy`. __Tip:__ you can get name of the class (metric) by issuing `metric.__class__.__name__`\n",
    "\n",
    "\n",
    "## Running the whole system\n",
    "\n",
    "Instantiate `ClassificationSystem` with necessary arguments and run `train`, `validate` and `test` methods.\n",
    "\n",
    "Verify your scores using tensorboard's GUI.\n",
    " \n",
    "    \n",
    "> __Additional:__ How to add `scheduler`s to our implementation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taken-shelf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here, have fun :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-commonwealth",
   "metadata": {},
   "source": [
    "# Challenges\n",
    "\n",
    "## Assessment\n",
    "\n",
    "- What are the other options to turn off gradient computations? See [PyTorch documentation](https://pytorch.org/docs/stable/notes/autograd.html#locally-disable-grad-doc). Why would you use one over the other?\n",
    "- What is gradient accumulation and how could one program it using PyTorch?\n",
    "\n",
    "## Non-assessment\n",
    "\n",
    "- Check [PyTorch Ignite](https://pytorch.org/ignite/index.html) a third-party  framework used to remove some boilerplate code from your training loop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
